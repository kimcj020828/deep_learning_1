'''
신경망 학습의 절차

[전체]
신경망에는 적응 가능한 가중치와 평향이 있고, 이 가중치와 편향을 훈련데이터에 적응하도록 조정하는 과정을 '학습'이라 한다.
학습은 다음과 같이 4단계로 수행한다.

[1단계-미니배치]
훈련데이터 중 일부를 무작위로 가져온다. 이렇게 선별한 데이터를 미니배치라 하며,
그 미니배치의 손실함수 값을 줄이는 것이 목표이다.

[2간계-기울기 산출]
미니배치의 손실 함수 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구합니다.
기울기는 손실 함수의 값을 가장 작게 하는 방향을 제시한다.

[3단계 매개변수 갱신]
가중치 매개변수를 기울기 방향으로 아주 조금씩 갱신한다.

[4단계-반복]
1~3단계를 반복한다.

위의 4단계를 '미니배치'를 이용한 무작위 선정으로 인해 '확률적 경사 하강법(stochastic gradient descent,SGD)'이라고 부른다.
디부분의 딥러닝 프레임워크는 확률적 경사 하강법의 영어 머리글자를 딴 SGD라는 함수로 이 기능을 구현했다.
'''


'''
아래는 손글씨 숫자를 학습하는 신경망을 구현해보겠다.
여기서는 2층 신경망(은닉층 1개인 네트워크)을 대상으로 MNIST 데이터셋을 사용하여 학습을 수행할 예정이다.
'''